{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import sklearn as sk\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import matplotlib.pyplot as plt\n",
    "#from tcn import TCN\n",
    "#from tensorflow import keras\n",
    "#import tensorflow as tf\n",
    "#from sklearn import metrics\n",
    "#import sqlite3\n",
    "#import time\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from tcn import TCN\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import sqlite3\n",
    "import time\n",
    "import pickle as pkl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alle funktioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def PullFromDB(event, db_file):\n",
    "##    events = batch['event_no'].reset_index(drop = True)\n",
    "#    with sqlite3.connect(db_file) as con:\n",
    "#        query = 'select event_no, dom_x, dom_y, dom_z, charge_log10, time from features where event_no ==' + str(event)\n",
    "#        features = pd.read_sql(query, con)\n",
    "#        query = 'select zenith from truth where event_no == ' + str(event)\n",
    "#        truth = pd.read_sql(query, con)\n",
    "#    #truth = 10**truth\n",
    "#    features = features.sort_values('time')\n",
    "#    return features, truth.values\n",
    "#\n",
    "#\n",
    "#def TransformFeaturesToInput(features):\n",
    "#    feat = np.array(features.drop(columns='event_no'))\n",
    "#    feat = np.reshape(feat, (1, feat.shape[0], feat.shape[1]))\n",
    "#    return feat    \n",
    "#\n",
    "#def TransformTruthToInput(truth):\n",
    "##    truth = truth.values[0][0]\n",
    "#    #out = tf.convert_to_tensor([tf.math.sin(truth) , tf.math.cos(truth)])\n",
    "##    truth = 10**truth\n",
    "#    out = [np.sin(truth), np.cos(truth)]\n",
    "#    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def GetTrainingEvents(db_file, n_events):\n",
    "#    t0 = time.time()\n",
    "#    with sqlite3.connect(db_file) as con:\n",
    "#        query = 'select event_no from truth where stopped_muon == 1 and abs(pid) == 13 limit %s'%n_events[0]\n",
    "#        stopped_events = pd.read_sql(query,con)\n",
    "#        query = 'select event_no from truth where stopped_muon == 0 and abs(pid) == 13 limit %s'%n_events[1]\n",
    "#        not_stopped_events = pd.read_sql(query,con)\n",
    "#\n",
    "#    events = stopped_events.append(not_stopped_events, ignore_index = True) # 50 / 50 fordeling\n",
    "#    events = events.sample(frac = 1).reset_index(drop = True) # det betyder bare at events bliver shuffled.\n",
    "#    t1 = time.time()\n",
    "##    print('GetTrainingEvents executed in ', np.round(t1-t0,4),'s')\n",
    "#    return events\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#def GetValidationEvents(db_file, training_events, n_events):\n",
    "#    t0 = time.time()\n",
    "#    with sqlite3.connect(db_file) as con:\n",
    "#        query = 'select event_no from truth where stopped_muon == 1 and abs(pid) == 13 and event_no not in %s limit %s'%( str(tuple(training_events)), n_events[0])\n",
    "#        stopped_events = pd.read_sql(query,con)\n",
    "#        query = 'select event_no from truth where stopped_muon == 0 and abs(pid) == 13 and event_no not in %s  limit %s' %(str(tuple(training_events)), n_events[1])\n",
    "#        not_stopped_events = pd.read_sql(query,con)\n",
    "#\n",
    "#    events = stopped_events.append(not_stopped_events, ignore_index = True) # 50 / 50 fordeling\n",
    "##    events = events.sample(frac = 1).reset_index(drop = True) # det betyder bare at events bliver shuffled.\n",
    "#    t1 = time.time()\n",
    "#    print('GetValidationEvents executed in ',np.round(t1-t0,1),'s')\n",
    "#    return events\n",
    "#\n",
    "#def FixMyInput(events, db_file, max_length, max_event_size):\n",
    "#    t0 = time.time()\n",
    "#    padded_input = []\n",
    "#    input_targets_list = []\n",
    "#    a,b = 0, 1        \n",
    "#    for i in range(int(len(events))):   ### Den her del skal optimeres......\n",
    "#        input_feature_list = []\n",
    "#\n",
    "#        for event in events[a:b]:\n",
    "#            features, truth = PullFromDB(event, db_file)\n",
    "#            if len(features) < max_event_size:\n",
    "#                input_feats = TransformFeaturesToInput(features)\n",
    "#                input_feature_list.append(input_feats)\n",
    "#                input_targs = TransformTruthToInput(truth)\n",
    "#                input_targets_list.append(input_targs)\n",
    "#\n",
    "#    #Padder events, så hver batch har samme dimensioner   \n",
    "#\n",
    "#        k = 0\n",
    "#        for feature in input_feature_list:            #### har prøvet at bruge nogle af de padding layers som er i biblioteket?\n",
    "#                temp = np.zeros([1, max_length, 5])\n",
    "#                temp[:, :feature.shape[1], :] = feature\n",
    "#                padded_input.append(temp)        \n",
    "#                padded_features = np.concatenate(padded_input)\n",
    "#                padded_target = np.concatenate(input_targets_list).reshape((len(input_targets_list),2))\n",
    "#\n",
    "#        a += 1\n",
    "#        b += 1\n",
    "#    t1 = time.time()\n",
    "##    print('FixMyInput executed in ', np.round(t1-t0,1) ,'s')\n",
    "#    return padded_features, padded_target, max_length\n",
    "#    \n",
    "#    \n",
    "#def Train(model, events, batch_size, db_file, max_length, n_epochs, max_event_size, Metrics=None):\n",
    "#    t0 = time.time()\n",
    "#    n_batches = int(len(events)/batch_size) #\n",
    "#    print('Getting %s batches'%(n_batches)) #\n",
    "#    event_list = np.array_split(events, n_batches) #\n",
    "#    k = 1\n",
    "#    batches = []\n",
    "#    for event_batch in event_list:\n",
    "#        print('Getting Batch %s / %s'%(k,n_batches))\n",
    "#        batch_features, batch_truth, _ = FixMyInput(event_batch['event_no'].reset_index(drop = True), db_file, max_length, max_event_size) #\n",
    "#        batches.append([batch_features, batch_truth]) #\n",
    "#        k +=1\n",
    "#    Training_Losses = []\n",
    "#    for epoch in range(n_epochs): \n",
    "#        epoch_loss = 0\n",
    "#        for batch in batches:\n",
    "#            #print(batch[0].shape, batch[1].shape)\n",
    "#            batch_loss = model.train_on_batch(x = batch[0], y = batch[1])\n",
    "#            Training_Losses.append(batch_loss)\n",
    "#            epoch_loss +=batch_loss\n",
    "#            \n",
    "#        print(epoch_loss)\n",
    "#        print('TRAINING EPOCH: %s / %s'%(epoch+1, n_epochs))\n",
    "#\n",
    "#    t1 = time.time()\n",
    "#    print('Training executed in', np.round((t1-t0)/60,1),'m')\n",
    "#    return model, Training_Losses\n",
    "#\n",
    "#def Predict(model, events, batch_size, db_file, max_length, max_event_size):\n",
    "#    t0 = time.time()\n",
    "#    n_batches = int(np.ceil(len(events)/batch_size))\n",
    "#    print('Getting %s batches'%(n_batches))\n",
    "#    event_list = np.array_split(events, n_batches)\n",
    "#    k = 1\n",
    "#    predictions = []\n",
    "#    truth       = []\n",
    "#    for event_batch in event_list:\n",
    "#        print('Getting Batch %s / %s'%(k, n_batches))\n",
    "#        \n",
    "#        batch_features, batch_truth, _ = FixMyInput(event_batch['event_no'].reset_index(drop = True), db_file, max_length, max_event_size)\n",
    "#        out = model.predict(x = batch_features, batch_size = batch_size)\n",
    "#        predictions.extend(out)\n",
    "#        truth.extend(batch_truth)\n",
    "#        k +=1\n",
    "#    t1 = time.time()\n",
    "#    print('Predict executed in', np.round(t1-t0,4), 's')\n",
    "#    return predictions, truth\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skræddersyet funktion af model.fit\n",
    "def Train(model, batches):# events, batch_size, db_file, max_length, n_epochs, max_event_size):\n",
    "    #n_batches = int(len(events)/batch_size)\n",
    "    #print('Getting %s batches'%(n_batches))\n",
    "    #event_list = np.array_split(events,n_batches)\n",
    "    #k = 1\n",
    "    #batches = []\n",
    "    #for event_batch in event_list:\n",
    "    #    print('Getting Batch %s / %s'%(k,n_batches))\n",
    "    #    batch_features, batch_truth, _ = FixMyInput(event_batch['event_no'].reset_index(drop = True), db_file, max_length, max_event_size)\n",
    "    #    batches.append([batch_features, batch_truth])\n",
    "    #    k +=1\n",
    "    Training_Losses = []\n",
    "    #Training_Losses\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        print('TRAINING EPOCH: %s / %s'%(epoch+1, n_epochs))\n",
    "        \n",
    "        for batch in batches:\n",
    "            #print(batch[0].shape)\n",
    "            #print(np.shape(batch[1]))\n",
    "           \n",
    "            batch_loss = model.train_on_batch(x = batch[0], y = batch[1])\n",
    "            #model.train_on_batch(x = batch[0], y = batch[1])\n",
    "            Training_Losses.append(batch_loss)\n",
    "            epoch_loss +=batch_loss\n",
    "            \n",
    "        print(epoch_loss)\n",
    "        \n",
    "        model.save('Model_at_epoch'+str(epoch+0))\n",
    "        with open('Loss_at_'+str(epoch+0)+'.pkl','wb') as f:\n",
    "            pkl.dump(Training_Losses, f)\n",
    "            \n",
    "    print('training done!')\n",
    "    return model, Training_Losses\n",
    "\n",
    "def Predict(model, batches):#, batch_size):\n",
    "    predictions = []\n",
    "    truth = []\n",
    "    for event_batch in batches:\n",
    "        out = model.predict(event_batch[0])#, batch_size)\n",
    "        predictions.extend(out)\n",
    "        truth.extend(event_batch[1])\n",
    "    print('prediction done!')\n",
    "    return predictions, truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('500k_zenith_train_final.pkl','rb') as f:\n",
    "    events = pkl.load(f)\n",
    "#print(np.shape(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events = events#[70:]\n",
    "#validation_events = events[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('200k_zenith_val_final.pkl','rb') as f:\n",
    "    events2 = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_events = events2#[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(train_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(validation_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db_file = 'rasmus_classification_muon_3neutrino_3mio.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODEL CONFIGURATION\n",
    "n_filters = 32 #64\n",
    "kernel_size = 5\n",
    "output_dim = 2\n",
    "lr = 1e-3\n",
    "batch_size = 1000\n",
    "#N_muons = 1000\n",
    "#n_batches = int(np.ceil(N_muons/batch_size))\n",
    "#n_events = [int(N_muons/2), int(N_muons/2)]\n",
    "#n_validation_events = [int(N_muons/10), int(N_muons/10)]\n",
    "\n",
    "#n_events = [250000,250000]\n",
    "\n",
    "n_epochs = 200\n",
    "max_event_size = 250\n",
    "max_length = max_event_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_events = GetTrainingEvents(db_file, n_events)\n",
    "#validation_events = GetValidationEvents(db_file, train_events['event_no'], n_validation_events)  # gets events for validation that is NOT in training \n",
    "#all_events = train_events.append(validation_events, ignore_index = True)\n",
    "#max_length = CalculateMaxLength(db_file, all_events['event_no'], max_event_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_model_26(max_length, N_filters,kernel_size, output_dim):\n",
    "    i = tf.keras.Input(batch_shape = (None, max_length,7))\n",
    "    o = TCN(\n",
    "        nb_filters = N_filters,\n",
    "        kernel_size = kernel_size,\n",
    "        #nb_stacks = 1,\n",
    "        #dilations=[1, 2, 4, 8, 16, 32],\n",
    "        #padding=\"causal\",\n",
    "        #use_skip_connections = False,\n",
    "        dropout_rate = 0.001,\n",
    "        return_sequences = False,\n",
    "        activation = tf.keras.layers.LeakyReLU()#\n",
    "        #kernel_initializer=\"he_normal\",\n",
    "        #use_layer_norm=False,\n",
    "        #use_batch_norm = False,\n",
    "     )(i)\n",
    "    o = tf.keras.layers.Dense(N_filters, activation = tf.keras.layers.LeakyReLU())(o) \n",
    "    o = tf.keras.layers.Dropout(0.01)(o)\n",
    "    o = tf.keras.layers.Dense(N_filters, activation = tf.keras.layers.LeakyReLU())(o)\n",
    "    \n",
    "    o = tf.keras.layers.Dense(output_dim, activation = 'tanh')(o)\n",
    "    model = tf.keras.models.Model(inputs=[i], outputs=[o])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sincosloss(y_true, y_pred): # y_true = [sin(zenith), cos(zenith)]\n",
    "    #print(y_true.shape)\n",
    "    #print(y_pred.shape)\n",
    "    \n",
    "    thetruth = tf.math.atan2(y_true[:,0], y_true[:,1])\n",
    "    thepred = tf.math.atan2(y_pred[:,0], y_pred[:,1])\n",
    "    co = 1- tf.math.cos(thetruth-thepred)\n",
    "    co = tf.reduce_sum(co)\n",
    "    \n",
    "    return co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tcn_model_26(max_length, n_filters, kernel_size, output_dim)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss = sincosloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('Model_at_epoch14/variables/variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH: 1 / 200\n",
      "20214.20912361145\n",
      "WARNING:tensorflow:From C:\\Users\\frede\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\frede\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch0\\assets\n",
      "TRAINING EPOCH: 2 / 200\n",
      "15615.875064849854\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch1\\assets\n",
      "TRAINING EPOCH: 3 / 200\n",
      "14252.993970870972\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch2\\assets\n",
      "TRAINING EPOCH: 4 / 200\n",
      "13300.63935661316\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch3\\assets\n",
      "TRAINING EPOCH: 5 / 200\n",
      "12618.462078094482\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch4\\assets\n",
      "TRAINING EPOCH: 6 / 200\n",
      "12143.740423202515\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch5\\assets\n",
      "TRAINING EPOCH: 7 / 200\n",
      "11786.586183547974\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch6\\assets\n",
      "TRAINING EPOCH: 8 / 200\n",
      "11472.72579574585\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch7\\assets\n",
      "TRAINING EPOCH: 9 / 200\n",
      "11219.149473190308\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch8\\assets\n",
      "TRAINING EPOCH: 10 / 200\n",
      "10972.91810798645\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch9\\assets\n",
      "TRAINING EPOCH: 11 / 200\n",
      "10752.198106765747\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch10\\assets\n",
      "TRAINING EPOCH: 12 / 200\n",
      "10520.61180305481\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch11\\assets\n",
      "TRAINING EPOCH: 13 / 200\n",
      "10310.257816314697\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch12\\assets\n",
      "TRAINING EPOCH: 14 / 200\n",
      "10100.691837310791\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch13\\assets\n",
      "TRAINING EPOCH: 15 / 200\n",
      "9913.005840301514\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch14\\assets\n",
      "TRAINING EPOCH: 16 / 200\n",
      "9755.66314125061\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch15\\assets\n",
      "TRAINING EPOCH: 17 / 200\n",
      "9585.822917938232\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch16\\assets\n",
      "TRAINING EPOCH: 18 / 200\n",
      "9433.83971786499\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch17\\assets\n",
      "TRAINING EPOCH: 19 / 200\n",
      "9269.2744846344\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch18\\assets\n",
      "TRAINING EPOCH: 20 / 200\n",
      "9143.811856269836\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch19\\assets\n",
      "TRAINING EPOCH: 21 / 200\n",
      "9023.785535812378\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch20\\assets\n",
      "TRAINING EPOCH: 22 / 200\n",
      "8897.213025093079\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch21\\assets\n",
      "TRAINING EPOCH: 23 / 200\n",
      "8790.294381141663\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch22\\assets\n",
      "TRAINING EPOCH: 24 / 200\n",
      "8666.243752479553\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch23\\assets\n",
      "TRAINING EPOCH: 25 / 200\n",
      "8559.158074378967\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch24\\assets\n",
      "TRAINING EPOCH: 26 / 200\n",
      "8461.5150308609\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch25\\assets\n",
      "TRAINING EPOCH: 27 / 200\n",
      "8363.938462257385\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch26\\assets\n",
      "TRAINING EPOCH: 28 / 200\n",
      "8265.07678604126\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch27\\assets\n",
      "TRAINING EPOCH: 29 / 200\n",
      "8181.243216514587\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch28\\assets\n",
      "TRAINING EPOCH: 30 / 200\n",
      "8098.076415061951\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch29\\assets\n",
      "TRAINING EPOCH: 31 / 200\n",
      "8016.677289962769\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch30\\assets\n",
      "TRAINING EPOCH: 32 / 200\n",
      "7952.9143924713135\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch31\\assets\n",
      "TRAINING EPOCH: 33 / 200\n",
      "7882.367728233337\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch32\\assets\n",
      "TRAINING EPOCH: 34 / 200\n",
      "7836.719582557678\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch33\\assets\n",
      "TRAINING EPOCH: 35 / 200\n",
      "7757.476165771484\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch34\\assets\n",
      "TRAINING EPOCH: 36 / 200\n",
      "7701.586919784546\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch35\\assets\n",
      "TRAINING EPOCH: 37 / 200\n",
      "7646.399765968323\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch36\\assets\n",
      "TRAINING EPOCH: 38 / 200\n",
      "7592.414964675903\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch37\\assets\n",
      "TRAINING EPOCH: 39 / 200\n",
      "7535.950163841248\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch38\\assets\n",
      "TRAINING EPOCH: 40 / 200\n",
      "7478.023461341858\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch39\\assets\n",
      "TRAINING EPOCH: 41 / 200\n",
      "7407.018002510071\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch40\\assets\n",
      "TRAINING EPOCH: 42 / 200\n",
      "7366.699119567871\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch41\\assets\n",
      "TRAINING EPOCH: 43 / 200\n",
      "7327.468572616577\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch42\\assets\n",
      "TRAINING EPOCH: 44 / 200\n",
      "7278.653280258179\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch43\\assets\n",
      "TRAINING EPOCH: 45 / 200\n",
      "7244.651048660278\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch44\\assets\n",
      "TRAINING EPOCH: 46 / 200\n",
      "7206.257696151733\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch45\\assets\n",
      "TRAINING EPOCH: 47 / 200\n",
      "7194.589912414551\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch46\\assets\n",
      "TRAINING EPOCH: 48 / 200\n",
      "7152.1041431427\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch47\\assets\n",
      "TRAINING EPOCH: 49 / 200\n",
      "7145.10418510437\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch48\\assets\n",
      "TRAINING EPOCH: 50 / 200\n",
      "7121.27843952179\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch49\\assets\n",
      "TRAINING EPOCH: 51 / 200\n",
      "7090.123508453369\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch50\\assets\n",
      "TRAINING EPOCH: 52 / 200\n",
      "7045.304823875427\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch51\\assets\n",
      "TRAINING EPOCH: 53 / 200\n",
      "6993.984934806824\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch52\\assets\n",
      "TRAINING EPOCH: 54 / 200\n",
      "6934.652206420898\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch53\\assets\n",
      "TRAINING EPOCH: 55 / 200\n",
      "6905.192529678345\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch54\\assets\n",
      "TRAINING EPOCH: 56 / 200\n",
      "6904.349551200867\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch55\\assets\n",
      "TRAINING EPOCH: 57 / 200\n",
      "6850.852465629578\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch56\\assets\n",
      "TRAINING EPOCH: 58 / 200\n",
      "6832.279916763306\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch57\\assets\n",
      "TRAINING EPOCH: 59 / 200\n",
      "6818.38182258606\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch58\\assets\n",
      "TRAINING EPOCH: 60 / 200\n",
      "6775.322002410889\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch59\\assets\n",
      "TRAINING EPOCH: 61 / 200\n",
      "6723.695610046387\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch60\\assets\n",
      "TRAINING EPOCH: 62 / 200\n",
      "6717.236410140991\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch61\\assets\n",
      "TRAINING EPOCH: 63 / 200\n",
      "6684.6715087890625\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch62\\assets\n",
      "TRAINING EPOCH: 64 / 200\n",
      "6653.937744140625\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch63\\assets\n",
      "TRAINING EPOCH: 65 / 200\n",
      "6640.186012268066\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch64\\assets\n",
      "TRAINING EPOCH: 66 / 200\n",
      "6646.905271530151\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch65\\assets\n",
      "TRAINING EPOCH: 67 / 200\n",
      "6660.622296333313\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch66\\assets\n",
      "TRAINING EPOCH: 68 / 200\n",
      "6622.064041137695\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch67\\assets\n",
      "TRAINING EPOCH: 69 / 200\n",
      "6595.878896713257\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch68\\assets\n",
      "TRAINING EPOCH: 70 / 200\n",
      "6554.157095909119\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch69\\assets\n",
      "TRAINING EPOCH: 71 / 200\n",
      "6535.071809768677\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch70\\assets\n",
      "TRAINING EPOCH: 72 / 200\n",
      "6497.9419803619385\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch71\\assets\n",
      "TRAINING EPOCH: 73 / 200\n",
      "6486.563999176025\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch72\\assets\n",
      "TRAINING EPOCH: 74 / 200\n",
      "6450.830421447754\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch73\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH: 75 / 200\n",
      "6447.590304374695\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch74\\assets\n",
      "TRAINING EPOCH: 76 / 200\n",
      "6441.678027153015\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch75\\assets\n",
      "TRAINING EPOCH: 77 / 200\n",
      "6412.538066864014\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch76\\assets\n",
      "TRAINING EPOCH: 78 / 200\n",
      "6383.2344398498535\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch77\\assets\n",
      "TRAINING EPOCH: 79 / 200\n",
      "6326.457465171814\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch78\\assets\n",
      "TRAINING EPOCH: 80 / 200\n",
      "6317.939732551575\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch79\\assets\n",
      "TRAINING EPOCH: 81 / 200\n",
      "6282.188626289368\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch80\\assets\n",
      "TRAINING EPOCH: 82 / 200\n",
      "6254.5067348480225\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch81\\assets\n",
      "TRAINING EPOCH: 83 / 200\n",
      "6257.587416648865\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch82\\assets\n",
      "TRAINING EPOCH: 84 / 200\n",
      "6231.730746269226\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch83\\assets\n",
      "TRAINING EPOCH: 85 / 200\n",
      "6207.920497894287\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch84\\assets\n",
      "TRAINING EPOCH: 86 / 200\n",
      "6205.878999710083\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch85\\assets\n",
      "TRAINING EPOCH: 87 / 200\n",
      "6189.791181564331\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch86\\assets\n",
      "TRAINING EPOCH: 88 / 200\n",
      "6185.420642852783\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch87\\assets\n",
      "TRAINING EPOCH: 89 / 200\n",
      "6209.824372291565\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch88\\assets\n",
      "TRAINING EPOCH: 90 / 200\n",
      "6238.199024200439\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch89\\assets\n",
      "TRAINING EPOCH: 91 / 200\n",
      "6243.753310203552\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch90\\assets\n",
      "TRAINING EPOCH: 92 / 200\n",
      "6198.844410896301\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch91\\assets\n",
      "TRAINING EPOCH: 93 / 200\n",
      "6164.503698348999\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch92\\assets\n",
      "TRAINING EPOCH: 94 / 200\n",
      "6125.245746612549\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch93\\assets\n",
      "TRAINING EPOCH: 95 / 200\n",
      "6085.132571220398\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch94\\assets\n",
      "TRAINING EPOCH: 96 / 200\n",
      "6077.824040412903\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch95\\assets\n",
      "TRAINING EPOCH: 97 / 200\n",
      "6054.235915184021\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch96\\assets\n",
      "TRAINING EPOCH: 98 / 200\n",
      "6048.058678627014\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch97\\assets\n",
      "TRAINING EPOCH: 99 / 200\n",
      "6033.821576118469\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch98\\assets\n",
      "TRAINING EPOCH: 100 / 200\n",
      "6015.506045341492\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch99\\assets\n",
      "TRAINING EPOCH: 101 / 200\n",
      "5997.745295524597\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch100\\assets\n",
      "TRAINING EPOCH: 102 / 200\n",
      "5995.64855670929\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch101\\assets\n",
      "TRAINING EPOCH: 103 / 200\n",
      "5997.271156311035\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch102\\assets\n",
      "TRAINING EPOCH: 104 / 200\n",
      "5978.489477157593\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch103\\assets\n",
      "TRAINING EPOCH: 105 / 200\n",
      "6001.466164588928\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch104\\assets\n",
      "TRAINING EPOCH: 106 / 200\n",
      "6044.1635665893555\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch105\\assets\n",
      "TRAINING EPOCH: 107 / 200\n",
      "6048.922364234924\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch106\\assets\n",
      "TRAINING EPOCH: 108 / 200\n",
      "6022.912328720093\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch107\\assets\n",
      "TRAINING EPOCH: 109 / 200\n",
      "5968.953762054443\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch108\\assets\n",
      "TRAINING EPOCH: 110 / 200\n",
      "5936.057302474976\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch109\\assets\n",
      "TRAINING EPOCH: 111 / 200\n",
      "5921.927158355713\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch110\\assets\n",
      "TRAINING EPOCH: 112 / 200\n",
      "5901.460636138916\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch111\\assets\n",
      "TRAINING EPOCH: 113 / 200\n",
      "5866.899168968201\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch112\\assets\n",
      "TRAINING EPOCH: 114 / 200\n",
      "5856.6031675338745\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch113\\assets\n",
      "TRAINING EPOCH: 115 / 200\n",
      "5846.604044914246\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch114\\assets\n",
      "TRAINING EPOCH: 116 / 200\n",
      "5858.630795478821\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch115\\assets\n",
      "TRAINING EPOCH: 117 / 200\n",
      "5854.251008987427\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch116\\assets\n",
      "TRAINING EPOCH: 118 / 200\n",
      "5843.769881248474\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch117\\assets\n",
      "TRAINING EPOCH: 119 / 200\n",
      "5823.672772407532\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch118\\assets\n",
      "TRAINING EPOCH: 120 / 200\n",
      "5836.840781211853\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch119\\assets\n",
      "TRAINING EPOCH: 121 / 200\n",
      "5818.314574241638\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch120\\assets\n",
      "TRAINING EPOCH: 122 / 200\n",
      "5801.403812408447\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch121\\assets\n",
      "TRAINING EPOCH: 123 / 200\n",
      "5774.955823898315\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch122\\assets\n",
      "TRAINING EPOCH: 124 / 200\n",
      "5759.126613616943\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch123\\assets\n",
      "TRAINING EPOCH: 125 / 200\n",
      "5753.088768005371\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch124\\assets\n",
      "TRAINING EPOCH: 126 / 200\n",
      "5747.672704696655\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch125\\assets\n",
      "TRAINING EPOCH: 127 / 200\n",
      "5733.187806129456\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch126\\assets\n",
      "TRAINING EPOCH: 128 / 200\n",
      "5722.928868293762\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch127\\assets\n",
      "TRAINING EPOCH: 129 / 200\n",
      "5710.082173347473\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch128\\assets\n",
      "TRAINING EPOCH: 130 / 200\n",
      "5712.816824913025\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch129\\assets\n",
      "TRAINING EPOCH: 131 / 200\n",
      "5707.682143211365\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch130\\assets\n",
      "TRAINING EPOCH: 132 / 200\n",
      "5695.460163116455\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch131\\assets\n",
      "TRAINING EPOCH: 133 / 200\n",
      "5700.1852951049805\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch132\\assets\n",
      "TRAINING EPOCH: 134 / 200\n",
      "5693.067825317383\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch133\\assets\n",
      "TRAINING EPOCH: 135 / 200\n",
      "5725.133185386658\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch134\\assets\n",
      "TRAINING EPOCH: 136 / 200\n",
      "5750.164827346802\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch135\\assets\n",
      "TRAINING EPOCH: 137 / 200\n",
      "5764.648396492004\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch136\\assets\n",
      "TRAINING EPOCH: 138 / 200\n",
      "5731.167586326599\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch137\\assets\n",
      "TRAINING EPOCH: 139 / 200\n",
      "5726.249207496643\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch138\\assets\n",
      "TRAINING EPOCH: 140 / 200\n",
      "5715.591156005859\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch139\\assets\n",
      "TRAINING EPOCH: 141 / 200\n",
      "5712.854934692383\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch140\\assets\n",
      "TRAINING EPOCH: 142 / 200\n",
      "5701.887950897217\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch141\\assets\n",
      "TRAINING EPOCH: 143 / 200\n",
      "5665.692363739014\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch142\\assets\n",
      "TRAINING EPOCH: 144 / 200\n",
      "5644.730220794678\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch143\\assets\n",
      "TRAINING EPOCH: 145 / 200\n",
      "5634.145787239075\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch144\\assets\n",
      "TRAINING EPOCH: 146 / 200\n",
      "5612.8119258880615\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch145\\assets\n",
      "TRAINING EPOCH: 147 / 200\n",
      "5603.759985923767\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch146\\assets\n",
      "TRAINING EPOCH: 148 / 200\n",
      "5600.663536071777\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch147\\assets\n",
      "TRAINING EPOCH: 149 / 200\n",
      "5574.443287849426\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch148\\assets\n",
      "TRAINING EPOCH: 150 / 200\n",
      "5564.993113517761\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch149\\assets\n",
      "TRAINING EPOCH: 151 / 200\n",
      "5564.509984970093\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch150\\assets\n",
      "TRAINING EPOCH: 152 / 200\n",
      "5559.655287742615\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch151\\assets\n",
      "TRAINING EPOCH: 153 / 200\n",
      "5556.30162525177\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch152\\assets\n",
      "TRAINING EPOCH: 154 / 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5551.129060745239\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch153\\assets\n",
      "TRAINING EPOCH: 155 / 200\n",
      "5545.646015167236\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch154\\assets\n",
      "TRAINING EPOCH: 156 / 200\n",
      "5561.66757106781\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch155\\assets\n",
      "TRAINING EPOCH: 157 / 200\n",
      "5568.067958831787\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch156\\assets\n",
      "TRAINING EPOCH: 158 / 200\n",
      "5607.074216842651\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch157\\assets\n",
      "TRAINING EPOCH: 159 / 200\n",
      "5645.6156969070435\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch158\\assets\n",
      "TRAINING EPOCH: 160 / 200\n",
      "5642.649172782898\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch159\\assets\n",
      "TRAINING EPOCH: 161 / 200\n",
      "5608.746284484863\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch160\\assets\n",
      "TRAINING EPOCH: 162 / 200\n",
      "5605.314651489258\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch161\\assets\n",
      "TRAINING EPOCH: 163 / 200\n",
      "5577.195611953735\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch162\\assets\n",
      "TRAINING EPOCH: 164 / 200\n",
      "5550.746932983398\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch163\\assets\n",
      "TRAINING EPOCH: 165 / 200\n",
      "5642.842759132385\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch164\\assets\n",
      "TRAINING EPOCH: 166 / 200\n",
      "5494.738243103027\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch165\\assets\n",
      "TRAINING EPOCH: 167 / 200\n",
      "5474.725666046143\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch166\\assets\n",
      "TRAINING EPOCH: 168 / 200\n",
      "5456.203174591064\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch167\\assets\n",
      "TRAINING EPOCH: 169 / 200\n",
      "5441.6231508255005\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch168\\assets\n",
      "TRAINING EPOCH: 170 / 200\n",
      "5444.272705078125\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch169\\assets\n",
      "TRAINING EPOCH: 171 / 200\n",
      "5432.5987911224365\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch170\\assets\n",
      "TRAINING EPOCH: 172 / 200\n",
      "5437.44242477417\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch171\\assets\n",
      "TRAINING EPOCH: 173 / 200\n",
      "5420.899432182312\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch172\\assets\n",
      "TRAINING EPOCH: 174 / 200\n",
      "5412.058213233948\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch173\\assets\n",
      "TRAINING EPOCH: 175 / 200\n",
      "5409.414430618286\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch174\\assets\n",
      "TRAINING EPOCH: 176 / 200\n",
      "5390.389276504517\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch175\\assets\n",
      "TRAINING EPOCH: 177 / 200\n",
      "5400.632197380066\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch176\\assets\n",
      "TRAINING EPOCH: 178 / 200\n",
      "5389.2415599823\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch177\\assets\n",
      "TRAINING EPOCH: 179 / 200\n",
      "5380.567427635193\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch178\\assets\n",
      "TRAINING EPOCH: 180 / 200\n",
      "5379.001452445984\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch179\\assets\n",
      "TRAINING EPOCH: 181 / 200\n",
      "5373.339091300964\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch180\\assets\n",
      "TRAINING EPOCH: 182 / 200\n",
      "5361.040132522583\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch181\\assets\n",
      "TRAINING EPOCH: 183 / 200\n",
      "5366.059042930603\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch182\\assets\n",
      "TRAINING EPOCH: 184 / 200\n",
      "5359.160614013672\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch183\\assets\n",
      "TRAINING EPOCH: 185 / 200\n",
      "5349.428688049316\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch184\\assets\n",
      "TRAINING EPOCH: 186 / 200\n",
      "5348.559699058533\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch185\\assets\n",
      "TRAINING EPOCH: 187 / 200\n",
      "5340.498815536499\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch186\\assets\n",
      "TRAINING EPOCH: 188 / 200\n",
      "5324.897877693176\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch187\\assets\n",
      "TRAINING EPOCH: 189 / 200\n",
      "5335.16419506073\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch188\\assets\n",
      "TRAINING EPOCH: 190 / 200\n",
      "5335.930577278137\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch189\\assets\n",
      "TRAINING EPOCH: 191 / 200\n",
      "5336.893164634705\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch190\\assets\n",
      "TRAINING EPOCH: 192 / 200\n",
      "5318.38182926178\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch191\\assets\n",
      "TRAINING EPOCH: 193 / 200\n",
      "5324.386985778809\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch192\\assets\n",
      "TRAINING EPOCH: 194 / 200\n",
      "5315.533835411072\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch193\\assets\n",
      "TRAINING EPOCH: 195 / 200\n",
      "5339.942768096924\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch194\\assets\n",
      "TRAINING EPOCH: 196 / 200\n",
      "5314.097376823425\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch195\\assets\n",
      "TRAINING EPOCH: 197 / 200\n",
      "5319.590711593628\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch196\\assets\n",
      "TRAINING EPOCH: 198 / 200\n",
      "5329.649136543274\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch197\\assets\n",
      "TRAINING EPOCH: 199 / 200\n",
      "5351.924077987671\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch198\\assets\n",
      "TRAINING EPOCH: 200 / 200\n",
      "5447.061092376709\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch199\\assets\n",
      "training done!\n",
      "29509.881 sec\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #trained_model, loss = Train(model, train_events, batch_size, db_file, max_length, n_epochs, max_event_size)\n",
    "    trained_model, loss = Train(model, train_events)#train_events, batch_size, db_file, max_length, n_epochs, max_event_size)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(round(end-start,3),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21084/60/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(np.array(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('zenit_loss2.pkl','wb') as f:\n",
    "#    pkl.dump(loss, f)C:\\Users\\frede\\python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('Model_at_epoch7')\n",
    "#model.load_weights('Model_at_epoch59/variables/variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-loaded\n",
      "prediction done!\n",
      "32.533 sec\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    \n",
    "    #trained_model=keras.models.load_model('Model_at_epoch8') \n",
    "    print('model-loaded')\n",
    "    start = time.time()\n",
    "    pred, truth = Predict(trained_model, validation_events)#, batch_size, db_file, max_length, max_event_size)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(round(end-start,3),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('zenith_pred2.pkl','wb') as f:\n",
    "#    pkl.dump(pred, f)\n",
    "#with open('zenith_truth2.pkl','wb') as f:\n",
    "#    pkl.dump(truth, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x169c1be11f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "zenith_pred = []\n",
    "zenith      = []\n",
    "for i in range(0,len(pred)):\n",
    "    zenith_pred.append(np.arctan2(pred[i][0],pred[i][1]))\n",
    "    zenith.append(np.arctan2(truth[i][0],truth[i][1]))\n",
    "    \n",
    "plt.hist(zenith, histtype = 'step', bins = 50, label ='truth') \n",
    "plt.hist(zenith_pred, histtype = 'step', bins = 50, label = 'pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.84383763],\n",
       "       [0.84383763, 1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(zenith_pred,zenith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#plt.hist2d(zenith,zenith_pred , bins =10)\n",
    "#plt.xlabel('Truth Zenith')\n",
    "#plt.ylabel('Pred. Zenith')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model.save('testy', save_format='h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
