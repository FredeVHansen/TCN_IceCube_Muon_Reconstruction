{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from tcn import TCN\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import sqlite3\n",
    "import time\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n"
     ]
    }
   ],
   "source": [
    "with open('johann_advice_1mil_train.pkl','rb') as f:\n",
    "#with open('200k_batch_size_1k_stopped_muon_training.pkl','rb') as f:\n",
    "    test = pkl.load(f)\n",
    "#print(np.shape(test))\n",
    "with open('johann_advice_200k_val.pkl','rb') as f:\n",
    "#with open('200k_batch_size_1k_stopped_muon_training.pkl','rb') as f:\n",
    "    test2 = pkl.load(f)\n",
    "train_events = test#[70:]\n",
    "validation_events = test2#[:70]\n",
    "\n",
    "validation_events_check = validation_events[:1]\n",
    "\n",
    "vallen = len(validation_events_check)\n",
    "vallen\n",
    "\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en funktion der laver validation_events om til X_val\n",
    "#needed for validation\n",
    "X_valQ, y_valQ = [], []\n",
    "for i in range(vallen):\n",
    "    X_valQ.append(validation_events_check[i][0])\n",
    "    y_valQ.append(validation_events_check[i][1])\n",
    "    \n",
    "for i in range(vallen):\n",
    "    lens = []\n",
    "    lens.append(X_valQ[i][:,0,0].shape)\n",
    "#    print(min(lens[0]))\n",
    "    min_len = int(min(lens[0]))\n",
    "    \n",
    "X_val, y_val = [], []\n",
    "for i in range(vallen):\n",
    "    X_val.append(np.array(X_valQ[i][:min_len, :, :]))\n",
    "    y_val.append(np.array(y_valQ[i][:min_len,:]))\n",
    "y_val = np.reshape(y_val,(1000,2))\n",
    "X_val = np.reshape(X_val,(1000,250,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 250, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    n_filters = 16 #32\n",
    "    kernel_size = 10 #3 #10\n",
    "    output_dim = 2\n",
    "    lr = 1e-3 #1e-4\n",
    "    batch_size = 100\n",
    "    n_epochs = 100#200\n",
    "    max_event_size = 250\n",
    "    #db_file = 'rasmus_classification_muon_3neutrino_3mio.db'\n",
    "    max_length = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skr√¶ddersyet funktion af model.fit\n",
    "def Train(model, batches, X_val):\n",
    "    Training_Losses = []\n",
    "    Training_auc_scores = []\n",
    "    #Training_Losses\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        print('TRAINING EPOCH: %s / %s'%(epoch+24, n_epochs))\n",
    "        \n",
    "        for batch in batches:\n",
    "            batch_loss = model.train_on_batch(x = batch[0], y = batch[1])            \n",
    "            Training_Losses.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            \n",
    "            \n",
    "        preds = model.predict(X_val)\n",
    "        #print(np.shape(preds))\n",
    "        fpr, tpr,_ = roc_curve(y_val[:,1], preds[:,1]/(preds[:,1] + preds[:,0]))\n",
    "        auc_score = auc(fpr,tpr)\n",
    "        #Training_auc_scores.append(auc_score)\n",
    "        print('AUC: ', auc_score)\n",
    "\n",
    "        \n",
    "        print('epoch loss: ', epoch_loss)\n",
    "        model.save('Model_at_epoch'+str(epoch+23))\n",
    "        with open('Loss_at_'+str(epoch+23)+'.pkl','wb') as f:\n",
    "            pkl.dump(Training_Losses, f)\n",
    "        \n",
    "    print('training done!')\n",
    "    return model, Training_Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_model_26(max_length, N_filters,kernel_size, output_dim):\n",
    "    i = tf.keras.Input(batch_shape = (None, max_length, 7))\n",
    "    o = TCN(\n",
    "        nb_filters = N_filters,\n",
    "        kernel_size = kernel_size,\n",
    "        #nb_stacks = 1,\n",
    "        #dilations=[1, 2, 4, 8, 16, 32],\n",
    "        #padding=\"causal\",\n",
    "        #use_skip_connections = False,\n",
    "        dropout_rate = 0.001,                                     #test/forslag fra Johann\n",
    "        return_sequences = False,\n",
    "        activation = tf.keras.layers.LeakyReLU()#\n",
    "        #kernel_initializer=\"he_normal\",\n",
    "        #use_layer_norm=False,\n",
    "        #use_batch_norm = False,\n",
    "     )(i)\n",
    "    #o = tf.keras.layers.Dense(32, activation = \"relu\")(o)\n",
    "    #o = tf.keras.layers.Dropout(0.01)(o)\n",
    "    #o = tf.keras.layers.Dense(16, activation = \"relu\")(o)\n",
    "    o = tf.keras.layers.Dense(N_filters, activation = \"relu\")(o)\n",
    "    o = tf.keras.layers.Dropout(0.01)(o)\n",
    "    o = tf.keras.layers.Dense(N_filters, activation = \"relu\")(o)\n",
    "       \n",
    "    \n",
    "    o = tf.keras.layers.Dense(output_dim, activation = 'sigmoid')(o)\n",
    "    model = tf.keras.models.Model(inputs=[i], outputs=[o])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tcn_model_26(max_length, n_filters, kernel_size, output_dim)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=tf.keras.losses.BinaryCrossentropy(from_logits= False, label_smoothing=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2c8ced79a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('Model_at_epoch22/variables/variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH: 24 / 100\n",
      "AUC:  0.8745663817663816\n",
      "epoch loss:  392.5313205718994\n",
      "WARNING:tensorflow:From C:\\Users\\frede\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\frede\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch23\\assets\n",
      "TRAINING EPOCH: 25 / 100\n",
      "AUC:  0.8754552706552707\n",
      "epoch loss:  391.71983870863914\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch24\\assets\n",
      "TRAINING EPOCH: 26 / 100\n",
      "AUC:  0.8743566951566952\n",
      "epoch loss:  390.87106239795685\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch25\\assets\n",
      "TRAINING EPOCH: 27 / 100\n",
      "AUC:  0.8755464387464389\n",
      "epoch loss:  390.06358417868614\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch26\\assets\n",
      "TRAINING EPOCH: 28 / 100\n",
      "AUC:  0.8757424501424501\n",
      "epoch loss:  389.24112659692764\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch27\\assets\n",
      "TRAINING EPOCH: 29 / 100\n",
      "AUC:  0.8762438746438745\n",
      "epoch loss:  388.53503826260567\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch28\\assets\n",
      "TRAINING EPOCH: 30 / 100\n",
      "AUC:  0.8745663817663818\n",
      "epoch loss:  387.75376480817795\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch29\\assets\n",
      "TRAINING EPOCH: 31 / 100\n",
      "AUC:  0.8753185185185184\n",
      "epoch loss:  387.18842700123787\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch30\\assets\n",
      "TRAINING EPOCH: 32 / 100\n",
      "AUC:  0.8754233618233618\n",
      "epoch loss:  386.597678989172\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch31\\assets\n",
      "TRAINING EPOCH: 33 / 100\n",
      "AUC:  0.8759019943019943\n",
      "epoch loss:  385.72327613830566\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch32\\assets\n",
      "TRAINING EPOCH: 34 / 100\n",
      "AUC:  0.8739099715099714\n",
      "epoch loss:  385.57497173547745\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch33\\assets\n",
      "TRAINING EPOCH: 35 / 100\n",
      "AUC:  0.8755327635327635\n",
      "epoch loss:  385.17901369929314\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch34\\assets\n",
      "TRAINING EPOCH: 36 / 100\n",
      "AUC:  0.8752866096866099\n",
      "epoch loss:  384.60645312070847\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch35\\assets\n",
      "TRAINING EPOCH: 37 / 100\n",
      "AUC:  0.8767680911680911\n",
      "epoch loss:  383.75669354200363\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch36\\assets\n",
      "TRAINING EPOCH: 38 / 100\n",
      "AUC:  0.8774381766381767\n",
      "epoch loss:  383.17106223106384\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch37\\assets\n",
      "TRAINING EPOCH: 39 / 100\n",
      "AUC:  0.8769048433048434\n",
      "epoch loss:  382.89910703897476\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch38\\assets\n",
      "TRAINING EPOCH: 40 / 100\n",
      "AUC:  0.8769960113960114\n",
      "epoch loss:  382.217780649662\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch39\\assets\n",
      "TRAINING EPOCH: 41 / 100\n",
      "AUC:  0.8783179487179488\n",
      "epoch loss:  381.55869445204735\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch40\\assets\n",
      "TRAINING EPOCH: 42 / 100\n",
      "AUC:  0.8772740740740742\n",
      "epoch loss:  381.0060714483261\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch41\\assets\n",
      "TRAINING EPOCH: 43 / 100\n",
      "AUC:  0.8768911680911681\n",
      "epoch loss:  380.8089434504509\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch42\\assets\n",
      "TRAINING EPOCH: 44 / 100\n",
      "AUC:  0.8764034188034189\n",
      "epoch loss:  379.9955173134804\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch43\\assets\n",
      "TRAINING EPOCH: 45 / 100\n",
      "AUC:  0.8761663817663817\n",
      "epoch loss:  379.9374423921108\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch44\\assets\n",
      "TRAINING EPOCH: 46 / 100\n",
      "AUC:  0.876079772079772\n",
      "epoch loss:  379.4855290353298\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch45\\assets\n",
      "TRAINING EPOCH: 47 / 100\n",
      "AUC:  0.8756376068376067\n",
      "epoch loss:  379.09672379493713\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch46\\assets\n",
      "TRAINING EPOCH: 48 / 100\n",
      "AUC:  0.8757698005698007\n",
      "epoch loss:  378.35630255937576\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch47\\assets\n",
      "TRAINING EPOCH: 49 / 100\n",
      "AUC:  0.8744706552706553\n",
      "epoch loss:  377.918708384037\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch48\\assets\n",
      "TRAINING EPOCH: 50 / 100\n",
      "AUC:  0.8770507122507122\n",
      "epoch loss:  377.7084493339062\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch49\\assets\n",
      "TRAINING EPOCH: 51 / 100\n",
      "AUC:  0.8763213675213675\n",
      "epoch loss:  377.2989433705807\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch50\\assets\n",
      "TRAINING EPOCH: 52 / 100\n",
      "AUC:  0.8770324786324788\n",
      "epoch loss:  376.92363354563713\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch51\\assets\n",
      "TRAINING EPOCH: 53 / 100\n",
      "AUC:  0.8775111111111111\n",
      "epoch loss:  376.5149807333946\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch52\\assets\n",
      "TRAINING EPOCH: 54 / 100\n",
      "AUC:  0.8769002849002849\n",
      "epoch loss:  376.2088239490986\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch53\\assets\n",
      "TRAINING EPOCH: 55 / 100\n",
      "AUC:  0.8777299145299144\n",
      "epoch loss:  375.853008300066\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch54\\assets\n",
      "TRAINING EPOCH: 56 / 100\n",
      "AUC:  0.8767726495726496\n",
      "epoch loss:  375.0882303714752\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch55\\assets\n",
      "TRAINING EPOCH: 57 / 100\n",
      "AUC:  0.8770142450142451\n",
      "epoch loss:  374.95202004909515\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch56\\assets\n",
      "TRAINING EPOCH: 58 / 100\n",
      "AUC:  0.8780991452991451\n",
      "epoch loss:  374.5310811698437\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch57\\assets\n",
      "TRAINING EPOCH: 59 / 100\n",
      "AUC:  0.8768136752136751\n",
      "epoch loss:  374.4565441906452\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch58\\assets\n",
      "TRAINING EPOCH: 60 / 100\n",
      "AUC:  0.8774472934472934\n",
      "epoch loss:  374.0335783958435\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch59\\assets\n",
      "TRAINING EPOCH: 61 / 100\n",
      "AUC:  0.8766769230769229\n",
      "epoch loss:  373.6724184155464\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch60\\assets\n",
      "TRAINING EPOCH: 62 / 100\n",
      "AUC:  0.8790336182336183\n",
      "epoch loss:  373.6775033175945\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch61\\assets\n",
      "TRAINING EPOCH: 63 / 100\n",
      "AUC:  0.8764991452991453\n",
      "epoch loss:  373.20734080672264\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch62\\assets\n",
      "TRAINING EPOCH: 64 / 100\n",
      "AUC:  0.8773287749287749\n",
      "epoch loss:  372.97410947084427\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch63\\assets\n",
      "TRAINING EPOCH: 65 / 100\n",
      "AUC:  0.878422792022792\n",
      "epoch loss:  372.5700009763241\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch64\\assets\n",
      "TRAINING EPOCH: 66 / 100\n",
      "AUC:  0.877374358974359\n",
      "epoch loss:  372.26706862449646\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch65\\assets\n",
      "TRAINING EPOCH: 67 / 100\n",
      "AUC:  0.8778757834757834\n",
      "epoch loss:  371.80568754673004\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch66\\assets\n",
      "TRAINING EPOCH: 68 / 100\n",
      "AUC:  0.8781811965811964\n",
      "epoch loss:  371.52526688575745\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch67\\assets\n",
      "TRAINING EPOCH: 69 / 100\n",
      "AUC:  0.8797128205128204\n",
      "epoch loss:  371.1442841887474\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch68\\assets\n",
      "TRAINING EPOCH: 70 / 100\n",
      "AUC:  0.8811031339031339\n",
      "epoch loss:  371.1963864862919\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch69\\assets\n",
      "TRAINING EPOCH: 71 / 100\n",
      "AUC:  0.8798495726495726\n",
      "epoch loss:  370.9553653895855\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch70\\assets\n",
      "TRAINING EPOCH: 72 / 100\n",
      "AUC:  0.878614245014245\n",
      "epoch loss:  370.6456462740898\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch71\\assets\n",
      "TRAINING EPOCH: 73 / 100\n",
      "AUC:  0.8776820512820512\n",
      "epoch loss:  370.30074194073677\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch72\\assets\n",
      "TRAINING EPOCH: 74 / 100\n",
      "AUC:  0.8767088319088319\n",
      "epoch loss:  370.1258631646633\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch73\\assets\n",
      "TRAINING EPOCH: 75 / 100\n",
      "AUC:  0.8777207977207977\n",
      "epoch loss:  369.8200185596943\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch74\\assets\n",
      "TRAINING EPOCH: 76 / 100\n",
      "AUC:  0.8780581196581196\n",
      "epoch loss:  369.61171931028366\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch75\\assets\n",
      "TRAINING EPOCH: 77 / 100\n",
      "AUC:  0.8784136752136751\n",
      "epoch loss:  369.52958911657333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model_at_epoch76\\assets\n",
      "TRAINING EPOCH: 78 / 100\n",
      "AUC:  0.8776980056980057\n",
      "epoch loss:  369.2020129561424\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch77\\assets\n",
      "TRAINING EPOCH: 79 / 100\n",
      "AUC:  0.8770507122507123\n",
      "epoch loss:  368.9009881615639\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch78\\assets\n",
      "TRAINING EPOCH: 80 / 100\n",
      "AUC:  0.8786871794871796\n",
      "epoch loss:  368.6873048841953\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch79\\assets\n",
      "TRAINING EPOCH: 81 / 100\n",
      "AUC:  0.8772786324786325\n",
      "epoch loss:  368.2965492606163\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch80\\assets\n",
      "TRAINING EPOCH: 82 / 100\n",
      "AUC:  0.8766495726495727\n",
      "epoch loss:  368.0664315521717\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch81\\assets\n",
      "TRAINING EPOCH: 83 / 100\n",
      "AUC:  0.8754096866096867\n",
      "epoch loss:  367.88650873303413\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch82\\assets\n",
      "TRAINING EPOCH: 84 / 100\n",
      "AUC:  0.8789880341880341\n",
      "epoch loss:  367.5707558989525\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch83\\assets\n",
      "TRAINING EPOCH: 85 / 100\n",
      "AUC:  0.8784729344729345\n",
      "epoch loss:  367.53454768657684\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch84\\assets\n",
      "TRAINING EPOCH: 86 / 100\n",
      "AUC:  0.8783589743589744\n",
      "epoch loss:  367.11238089203835\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch85\\assets\n",
      "TRAINING EPOCH: 87 / 100\n",
      "AUC:  0.8789880341880342\n",
      "epoch loss:  366.8320139348507\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch86\\assets\n",
      "TRAINING EPOCH: 88 / 100\n",
      "AUC:  0.8771282051282051\n",
      "epoch loss:  366.5417166352272\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch87\\assets\n",
      "TRAINING EPOCH: 89 / 100\n",
      "AUC:  0.8797128205128205\n",
      "epoch loss:  366.744465559721\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch88\\assets\n",
      "TRAINING EPOCH: 90 / 100\n",
      "AUC:  0.8798450142450143\n",
      "epoch loss:  366.8924322426319\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch89\\assets\n",
      "TRAINING EPOCH: 91 / 100\n",
      "AUC:  0.8801139601139603\n",
      "epoch loss:  366.4083189666271\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch90\\assets\n",
      "TRAINING EPOCH: 92 / 100\n",
      "AUC:  0.8803190883190883\n",
      "epoch loss:  366.3222982287407\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch91\\assets\n",
      "TRAINING EPOCH: 93 / 100\n",
      "AUC:  0.8798176638176638\n",
      "epoch loss:  366.0563058555126\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch92\\assets\n",
      "TRAINING EPOCH: 94 / 100\n",
      "AUC:  0.8805698005698005\n",
      "epoch loss:  365.9105777144432\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch93\\assets\n",
      "TRAINING EPOCH: 95 / 100\n",
      "AUC:  0.8808296296296297\n",
      "epoch loss:  365.5437844693661\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch94\\assets\n",
      "TRAINING EPOCH: 96 / 100\n",
      "AUC:  0.8817230769230768\n",
      "epoch loss:  365.05483850836754\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch95\\assets\n",
      "TRAINING EPOCH: 97 / 100\n",
      "AUC:  0.8814769230769229\n",
      "epoch loss:  365.0061188340187\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch96\\assets\n",
      "TRAINING EPOCH: 98 / 100\n",
      "AUC:  0.8798905982905982\n",
      "epoch loss:  364.61989855766296\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch97\\assets\n",
      "TRAINING EPOCH: 99 / 100\n",
      "AUC:  0.880191452991453\n",
      "epoch loss:  364.3533269762993\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch98\\assets\n",
      "TRAINING EPOCH: 100 / 100\n",
      "AUC:  0.8828717948717949\n",
      "epoch loss:  363.903301179409\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch99\\assets\n",
      "TRAINING EPOCH: 101 / 100\n",
      "AUC:  0.8811213675213674\n",
      "epoch loss:  363.6953679919243\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch100\\assets\n",
      "TRAINING EPOCH: 102 / 100\n",
      "AUC:  0.8824387464387464\n",
      "epoch loss:  364.0277490913868\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch101\\assets\n",
      "TRAINING EPOCH: 103 / 100\n",
      "AUC:  0.8828262108262107\n",
      "epoch loss:  363.5617722272873\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch102\\assets\n",
      "TRAINING EPOCH: 104 / 100\n",
      "AUC:  0.8818962962962962\n",
      "epoch loss:  363.1532411277294\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch103\\assets\n",
      "TRAINING EPOCH: 105 / 100\n",
      "AUC:  0.8826393162393162\n",
      "epoch loss:  363.169794768095\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch104\\assets\n",
      "TRAINING EPOCH: 106 / 100\n",
      "AUC:  0.8829584045584045\n",
      "epoch loss:  363.0465183854103\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch105\\assets\n",
      "TRAINING EPOCH: 107 / 100\n",
      "AUC:  0.881294586894587\n",
      "epoch loss:  362.6867699623108\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch106\\assets\n",
      "TRAINING EPOCH: 108 / 100\n",
      "AUC:  0.8821515669515668\n",
      "epoch loss:  362.7942353785038\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch107\\assets\n",
      "TRAINING EPOCH: 109 / 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3200aa167be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/GPU:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_events\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# train_events, batch_size, db_file, max_length,n_epochs, max_event_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-607fd0266e97>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(model, batches, X_val)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mTraining_Losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1698\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1699\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1700\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     \"\"\"\n\u001b[0;32m   1636\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m   def train_on_batch(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3574\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3575\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3576\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3577\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3578\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0m\u001b[0;32m    860\u001b[0m           self.handle, value_tensor, name=name)\n\u001b[0;32m    861\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, name)\u001b[0m\n\u001b[0;32m    140\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AssignVariableOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         tld.op_callbacks, resource, value)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()    \n",
    "    trained_model, loss = Train(model, train_events, validation_events)# train_events, batch_size, db_file, max_length,n_epochs, max_event_size)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(round(end-start,3),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(model, batches):#, batch_size):\n",
    "    predictions = []\n",
    "    truth = []\n",
    "    for event_batch in batches:\n",
    "        out = model.predict(event_batch[0])#, batch_size)\n",
    "        predictions.extend(out)\n",
    "        truth.extend(event_batch[1])\n",
    "    print('prediction done!')\n",
    "    return predictions, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    \n",
    "    pred,truth  = Predict(trained_model, validation_events)#, batch_size)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(round(end-start,3),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    pred = np.array(pred)\n",
    "    print(pred[0:5,:])\n",
    "    truth = np.array(truth)\n",
    "    \n",
    "    fpr, tpr,_ = roc_curve(truth[:,1], pred[:,1]/(pred[:,1] + pred[:,0]))\n",
    "    auc_score = auc(fpr,tpr)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.text(0.5,0.5,'AUC: %s'%round(auc_score,3))\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gem forskellige v√¶rdier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('stopped_muon_loss_0809_AUC.pkl','wb') as f:\n",
    "#    pkl.dump(loss, f)\n",
    "\n",
    "#with open('stopped_pred.pkl','wb') as f:\n",
    "#    pkl.dump(pred, f)\n",
    "\n",
    "#with open('stopped_ltruth.pkl','wb') as f:\n",
    "#    pkl.dump(truth, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gem model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('stopped_muon_0809_AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
