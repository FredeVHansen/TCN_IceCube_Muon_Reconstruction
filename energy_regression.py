{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from tcn import TCN\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import sqlite3\n",
    "import time\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = './Event_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('energy_500k_train_all.pkl','rb') as f:\n",
    "    train_events = pkl.load(f)\n",
    "    \n",
    "with open('energy_200k_val_all.pkl','rb') as f:\n",
    "    validation_events = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 200\n"
     ]
    }
   ],
   "source": [
    "vallen = len(validation_events)\n",
    "print(len(train_events), len(validation_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_valQ, y_valQ = [], []\n",
    "#for i in range(vallen):\n",
    "#    X_valQ.append(validation_events[i][0])\n",
    "#    y_valQ.append(validation_events[i][1])\n",
    "#    \n",
    "#for i in range(vallen):\n",
    "#    lens = []\n",
    "#    lens.append(X_valQ[i][:,0,0].shape)\n",
    "##    print(min(lens[0]))\n",
    "#    min_len = int(min(lens[0]))\n",
    "#\n",
    "#X_val, y_val = [], []\n",
    "#for i in range(vallen):\n",
    "#    X_val.append(np.array(X_valQ[i][:min_len, :, :]))\n",
    "#    y_val.append(y_valQ[i][:min_len,0])\n",
    "#\n",
    "#y_val = np.concatenate(y_val)\n",
    "#X_val = np.concatenate(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Skr√¶ddersyet funktion af model.fit\n",
    "#def Train(model, batches):\n",
    "#    Training_Losses = []\n",
    "#    Validation_Losses = [10e5]\n",
    "#    patience = 0\n",
    "#\n",
    "#    for epoch in range(n_epochs):       \n",
    "#        if patience < 5:\n",
    "#            epoch_loss = 0\n",
    "#            print('TRAINING EPOCH: %s / %s'%(epoch+1, n_epochs))\n",
    "#            for batch in batches:\n",
    "#                batch_loss = model.train_on_batch(x = batch[0], y = batch[1])\n",
    "#                epoch_loss +=batch_loss\n",
    "#            Training_Losses.append(epoch_loss)\n",
    "#            val_loss = model.evaluate(x = X_val, y = y_val, verbose=0)\n",
    "#            \n",
    "#            if val_loss < min(Validation_Losses):\n",
    "#                model.save('Earlystop')\n",
    "#                patience = 0\n",
    "#            else:\n",
    "#                patience += 1\n",
    "#    \n",
    "#            Validation_Losses.append(val_loss)\n",
    "#            print(Validation_Losses[1:][-5:])\n",
    "#            print('Epoch Loss:', np.round(epoch_loss,2))\n",
    "#            print('Validation Loss:', np.round(val_loss,2))\n",
    "#    \n",
    "#    print('training done!')\n",
    "#    return model, Training_Losses, Validation_Losses\n",
    "\n",
    "def Train(model, batches):# events, batch_size, db_file, max_length, n_epochs, max_event_size):\n",
    "    #n_batches = int(len(events)/batch_size)\n",
    "    #print('Getting %s batches'%(n_batches))\n",
    "    #event_list = np.array_split(events,n_batches)\n",
    "    #k = 1\n",
    "    #batches = []\n",
    "    #for event_batch in event_list:\n",
    "    #    print('Getting Batch %s / %s'%(k,n_batches))\n",
    "    #    batch_features, batch_truth, _ = FixMyInput(event_batch['event_no'].reset_index(drop = True), db_file, max_length, max_event_size)\n",
    "    #    batches.append([batch_features, batch_truth])\n",
    "    #    k +=1\n",
    "    Training_Losses = []\n",
    "    #Training_Losses\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        print('TRAINING EPOCH: %s / %s'%(epoch+35, n_epochs))\n",
    "        \n",
    "        for batch in batches:\n",
    "            #print(batch[0].shape)\n",
    "            #print(np.shape(batch[1]))\n",
    "           \n",
    "            batch_loss = model.train_on_batch(x = batch[0], y = batch[1])\n",
    "            #model.train_on_batch(x = batch[0], y = batch[1])\n",
    "            Training_Losses.append(batch_loss)\n",
    "            epoch_loss +=batch_loss\n",
    "            \n",
    "        print(epoch_loss)\n",
    "        \n",
    "        model.save('Model_at_epoch'+str(epoch+34))\n",
    "        with open('Loss_at_'+str(epoch+34)+'.pkl','wb') as f:\n",
    "            pkl.dump(Training_Losses, f)\n",
    "            \n",
    "    print('training done!')\n",
    "    return model, Training_Losses\n",
    "\n",
    "#def Predict(model, batches):#, batch_size):\n",
    "#    predictions = []\n",
    "#    truth = []\n",
    "#    for event_batch in batches:\n",
    "#        out = model.predict(event_batch[0])#, batch_size)\n",
    "#        predictions.extend(out)\n",
    "#        truth.extend(event_batch[1])\n",
    "#    print('prediction done!')\n",
    "#    return predictions, truth\n",
    "\n",
    "\n",
    "def Predict(model, batches):#, batch_size):\n",
    "    predictions = []\n",
    "    truth = []\n",
    "    for event_batch in batches:\n",
    "        out = model.predict(event_batch[0])\n",
    "        predictions.extend(out)\n",
    "        truth.extend(event_batch[1])\n",
    "    print('prediction done!')\n",
    "    return predictions, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODEL CONFIGURATION\n",
    "n_filters = 32\n",
    "kernel_size = 3\n",
    "output_dim = 1\n",
    "lr = 1e-3\n",
    "batch_size = 1000\n",
    "n_epochs = 200\n",
    "max_event_size = 250\n",
    "max_length = max_event_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = 'relu'#tf.keras.layers.LeakyReLU(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tcn_model_26(max_length, N_filters, kernel_size, output_dim):\n",
    "#    i = tf.keras.Input(batch_shape = (None, max_length, 7))\n",
    "#    o = TCN(nb_filters = n_filters, kernel_size = kernel_size, dropout_rate = 0.001, activation = act)(i)\n",
    "#    o = tf.keras.layers.Dense(128, activation = act)(o) \n",
    "#    o = tf.keras.layers.Dropout(0.01)(o)\n",
    "#    o = tf.keras.layers.Dense(64, activation = act)(o)\n",
    "#    o = tf.keras.layers.Dense(32, activation = act)(o) \n",
    "#    o = tf.keras.layers.Dense(16, activation = act)(o) \n",
    "#    o = tf.keras.layers.Dense(output_dim)(o)\n",
    "#    model = tf.keras.models.Model(inputs=[i], outputs=[o])\n",
    "#    return model\n",
    "def tcn_model_26(max_length, N_filters,kernel_size, output_dim):\n",
    "    i = tf.keras.Input(batch_shape = (None, max_length,7))\n",
    "    o = TCN(\n",
    "        nb_filters = N_filters,\n",
    "        kernel_size = kernel_size,\n",
    "        #nb_stacks = 1,\n",
    "        #dilations=[1, 2, 4, 8, 16, 32],\n",
    "        #padding=\"causal\",\n",
    "        #use_skip_connections = False,#True,\n",
    "        dropout_rate = 0.001,\n",
    "        return_sequences = False,\n",
    "        activation = 'elu',#tf.keras.layers.LeakyReLU(),#'relu',#tf.keras.layers.LeakyReLU()#\n",
    "        #kernel_initializer=\"he_normal\",\n",
    "        #use_batch_norm = False,\n",
    "        #use_layer_norm=False,\n",
    "        #use_weight_norm=False\n",
    "     )(i)\n",
    "    o = tf.keras.layers.Dense(N_filters, activation = \"elu\")(o) \n",
    "    o = tf.keras.layers.Dropout(0.01)(o)\n",
    "    o = tf.keras.layers.Dense(N_filters, activation = \"elu\")(o)\n",
    "    \n",
    "    o = tf.keras.layers.Dense(output_dim)(o)#tf.keras.layers.LeakyReLU)(o)\n",
    "    model = tf.keras.models.Model(inputs=[i], outputs=[o])\n",
    "    return model\n",
    "#def tcn_model_26(max_length, N_filters, kernel_size, output_dim):\n",
    "#    i = tf.keras.Input(batch_shape = (None, max_length, 7))\n",
    "#    o = TCN(nb_filters = n_filters, kernel_size = kernel_size, activation = act)(i)\n",
    "#    #o = tf.keras.layers.BatchNormalization()(o)\n",
    "#    o = tf.keras.layers.Dense(n_filters, activation = act)(o)\n",
    "#    #o = tf.keras.layers.BatchNormalization()(o)\n",
    "#    o = tf.keras.layers.Dropout(0.001)(o)\n",
    "#    o = tf.keras.layers.Dense(n_filters, activation = act)(o)\n",
    "#    o = tf.keras.layers.Dense(n_filters, activation = act)(o) \n",
    "#    o = tf.keras.layers.Dense(n_filters, activation = act)(o) \n",
    "#    o = tf.keras.layers.Dense(output_dim)(o)\n",
    "#    model = tf.keras.models.Model(inputs=[i], outputs=[o])\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.python.util.deprecation as deprecation\n",
    "#deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model = tcn_model_26(max_length, n_filters, kernel_size, output_dim)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss = 'mse')#tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1f5dfaccdc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('Model_at_epoch33/variables/variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH: 35 / 200\n",
      "9.979078210890293\n",
      "WARNING:tensorflow:From C:\\Users\\frede\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\frede\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch34\\assets\n",
      "TRAINING EPOCH: 36 / 200\n",
      "9.93414648808539\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch35\\assets\n",
      "TRAINING EPOCH: 37 / 200\n",
      "9.888363096863031\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch36\\assets\n",
      "TRAINING EPOCH: 38 / 200\n",
      "9.850750898942351\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch37\\assets\n",
      "TRAINING EPOCH: 39 / 200\n",
      "9.815844224765897\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch38\\assets\n",
      "TRAINING EPOCH: 40 / 200\n",
      "9.778329385444522\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch39\\assets\n",
      "TRAINING EPOCH: 41 / 200\n",
      "9.739586571231484\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch40\\assets\n",
      "TRAINING EPOCH: 42 / 200\n",
      "9.697402510792017\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch41\\assets\n",
      "TRAINING EPOCH: 43 / 200\n",
      "9.671654243022203\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch42\\assets\n",
      "TRAINING EPOCH: 44 / 200\n",
      "9.638510409742594\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch43\\assets\n",
      "TRAINING EPOCH: 45 / 200\n",
      "9.597116382792592\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch44\\assets\n",
      "TRAINING EPOCH: 46 / 200\n",
      "9.568939821794629\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch45\\assets\n",
      "TRAINING EPOCH: 47 / 200\n",
      "9.54556812159717\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch46\\assets\n",
      "TRAINING EPOCH: 48 / 200\n",
      "9.514504548162222\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch47\\assets\n",
      "TRAINING EPOCH: 49 / 200\n",
      "9.485024522989988\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch48\\assets\n",
      "TRAINING EPOCH: 50 / 200\n",
      "9.453690360300243\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch49\\assets\n",
      "TRAINING EPOCH: 51 / 200\n",
      "9.430286691524088\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch50\\assets\n",
      "TRAINING EPOCH: 52 / 200\n",
      "9.398274324834347\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch51\\assets\n",
      "TRAINING EPOCH: 53 / 200\n",
      "9.380467319861054\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch52\\assets\n",
      "TRAINING EPOCH: 54 / 200\n",
      "9.354887556284666\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch53\\assets\n",
      "TRAINING EPOCH: 55 / 200\n",
      "9.331347981467843\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch54\\assets\n",
      "TRAINING EPOCH: 56 / 200\n",
      "9.305783913470805\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch55\\assets\n",
      "TRAINING EPOCH: 57 / 200\n",
      "9.276303097605705\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch56\\assets\n",
      "TRAINING EPOCH: 58 / 200\n",
      "9.259643319062889\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch57\\assets\n",
      "TRAINING EPOCH: 59 / 200\n",
      "9.230463933199644\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch58\\assets\n",
      "TRAINING EPOCH: 60 / 200\n",
      "9.22166317421943\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch59\\assets\n",
      "TRAINING EPOCH: 61 / 200\n",
      "9.19061884842813\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch60\\assets\n",
      "TRAINING EPOCH: 62 / 200\n",
      "9.18989472091198\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch61\\assets\n",
      "TRAINING EPOCH: 63 / 200\n",
      "9.161239173263311\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch62\\assets\n",
      "TRAINING EPOCH: 64 / 200\n",
      "9.143172034993768\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch63\\assets\n",
      "TRAINING EPOCH: 65 / 200\n",
      "9.124979292973876\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch64\\assets\n",
      "TRAINING EPOCH: 66 / 200\n",
      "9.108924705535173\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch65\\assets\n",
      "TRAINING EPOCH: 67 / 200\n",
      "9.085346078500152\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch66\\assets\n",
      "TRAINING EPOCH: 68 / 200\n",
      "9.070763172581792\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch67\\assets\n",
      "TRAINING EPOCH: 69 / 200\n",
      "9.062184570357203\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch68\\assets\n",
      "TRAINING EPOCH: 70 / 200\n",
      "9.036376561969519\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch69\\assets\n",
      "TRAINING EPOCH: 71 / 200\n",
      "9.017938646487892\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch70\\assets\n",
      "TRAINING EPOCH: 72 / 200\n",
      "9.01009838655591\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch71\\assets\n",
      "TRAINING EPOCH: 73 / 200\n",
      "8.991597714833915\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch72\\assets\n",
      "TRAINING EPOCH: 74 / 200\n",
      "8.975520239211619\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch73\\assets\n",
      "TRAINING EPOCH: 75 / 200\n",
      "8.962896245531738\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch74\\assets\n",
      "TRAINING EPOCH: 76 / 200\n",
      "8.942999487742782\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch75\\assets\n",
      "TRAINING EPOCH: 77 / 200\n",
      "8.922404895536602\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch76\\assets\n",
      "TRAINING EPOCH: 78 / 200\n",
      "8.915503106079996\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch77\\assets\n",
      "TRAINING EPOCH: 79 / 200\n",
      "8.906660906039178\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch78\\assets\n",
      "TRAINING EPOCH: 80 / 200\n",
      "8.884531407617033\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch79\\assets\n",
      "TRAINING EPOCH: 81 / 200\n",
      "8.882455577142537\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch80\\assets\n",
      "TRAINING EPOCH: 82 / 200\n",
      "8.852249895222485\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch81\\assets\n",
      "TRAINING EPOCH: 83 / 200\n",
      "8.847208632156253\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch82\\assets\n",
      "TRAINING EPOCH: 84 / 200\n",
      "8.833867783658206\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch83\\assets\n",
      "TRAINING EPOCH: 85 / 200\n",
      "8.823979126289487\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch84\\assets\n",
      "TRAINING EPOCH: 86 / 200\n",
      "8.797567763365805\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch85\\assets\n",
      "TRAINING EPOCH: 87 / 200\n",
      "8.782310008071363\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch86\\assets\n",
      "TRAINING EPOCH: 88 / 200\n",
      "8.771788758225739\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch87\\assets\n",
      "TRAINING EPOCH: 89 / 200\n",
      "8.763115477748215\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch88\\assets\n",
      "TRAINING EPOCH: 90 / 200\n",
      "8.737116040661931\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch89\\assets\n",
      "TRAINING EPOCH: 91 / 200\n",
      "8.729301387444139\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch90\\assets\n",
      "TRAINING EPOCH: 92 / 200\n",
      "8.723188354633749\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch91\\assets\n",
      "TRAINING EPOCH: 93 / 200\n",
      "8.70713586639613\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch92\\assets\n",
      "TRAINING EPOCH: 94 / 200\n",
      "8.692497069016099\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch93\\assets\n",
      "TRAINING EPOCH: 95 / 200\n",
      "8.675811781547964\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch94\\assets\n",
      "TRAINING EPOCH: 96 / 200\n",
      "8.683842772617936\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch95\\assets\n",
      "TRAINING EPOCH: 97 / 200\n",
      "8.672201319597661\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch96\\assets\n",
      "TRAINING EPOCH: 98 / 200\n",
      "8.643769669346511\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch97\\assets\n",
      "TRAINING EPOCH: 99 / 200\n",
      "8.635072654113173\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch98\\assets\n",
      "TRAINING EPOCH: 100 / 200\n",
      "8.637381711043417\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch99\\assets\n",
      "TRAINING EPOCH: 101 / 200\n",
      "8.619016465730965\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch100\\assets\n",
      "TRAINING EPOCH: 102 / 200\n",
      "8.608098893426359\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch101\\assets\n",
      "TRAINING EPOCH: 103 / 200\n",
      "8.582184318453074\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch102\\assets\n",
      "TRAINING EPOCH: 104 / 200\n",
      "8.575158485211432\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch103\\assets\n",
      "TRAINING EPOCH: 105 / 200\n",
      "8.563345874659717\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch104\\assets\n",
      "TRAINING EPOCH: 106 / 200\n",
      "8.541285438463092\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch105\\assets\n",
      "TRAINING EPOCH: 107 / 200\n",
      "8.541284107603133\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch106\\assets\n",
      "TRAINING EPOCH: 108 / 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.531522457487881\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch107\\assets\n",
      "TRAINING EPOCH: 109 / 200\n",
      "8.52743562310934\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch108\\assets\n",
      "TRAINING EPOCH: 110 / 200\n",
      "8.517643197439611\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch109\\assets\n",
      "TRAINING EPOCH: 111 / 200\n",
      "8.50687453430146\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch110\\assets\n",
      "TRAINING EPOCH: 112 / 200\n",
      "8.479217330925167\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch111\\assets\n",
      "TRAINING EPOCH: 113 / 200\n",
      "8.47475069668144\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch112\\assets\n",
      "TRAINING EPOCH: 114 / 200\n",
      "8.463569674640894\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch113\\assets\n",
      "TRAINING EPOCH: 115 / 200\n",
      "8.454420930705965\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch114\\assets\n",
      "TRAINING EPOCH: 116 / 200\n",
      "8.454024617560208\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch115\\assets\n",
      "TRAINING EPOCH: 117 / 200\n",
      "8.438926562666893\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch116\\assets\n",
      "TRAINING EPOCH: 118 / 200\n",
      "8.419030556455255\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch117\\assets\n",
      "TRAINING EPOCH: 119 / 200\n",
      "8.405961400829256\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch118\\assets\n",
      "TRAINING EPOCH: 120 / 200\n",
      "8.390271520242095\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch119\\assets\n",
      "TRAINING EPOCH: 121 / 200\n",
      "8.396821854636073\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch120\\assets\n",
      "TRAINING EPOCH: 122 / 200\n",
      "8.381783875636756\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch121\\assets\n",
      "TRAINING EPOCH: 123 / 200\n",
      "8.36675956659019\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch122\\assets\n",
      "TRAINING EPOCH: 124 / 200\n",
      "8.36464832816273\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch123\\assets\n",
      "TRAINING EPOCH: 125 / 200\n",
      "8.350807166658342\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch124\\assets\n",
      "TRAINING EPOCH: 126 / 200\n",
      "8.34246858395636\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch125\\assets\n",
      "TRAINING EPOCH: 127 / 200\n",
      "8.347424016334116\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch126\\assets\n",
      "TRAINING EPOCH: 128 / 200\n",
      "8.329065196216106\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch127\\assets\n",
      "TRAINING EPOCH: 129 / 200\n",
      "8.313122770749032\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch128\\assets\n",
      "TRAINING EPOCH: 130 / 200\n",
      "8.309361178427935\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch129\\assets\n",
      "TRAINING EPOCH: 131 / 200\n",
      "8.292908411473036\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch130\\assets\n",
      "TRAINING EPOCH: 132 / 200\n",
      "8.29341390915215\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch131\\assets\n",
      "TRAINING EPOCH: 133 / 200\n",
      "8.281462904065847\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch132\\assets\n",
      "TRAINING EPOCH: 134 / 200\n",
      "8.248496633023024\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch133\\assets\n",
      "TRAINING EPOCH: 135 / 200\n",
      "8.263656887225807\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch134\\assets\n",
      "TRAINING EPOCH: 136 / 200\n",
      "8.253275560215116\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch135\\assets\n",
      "TRAINING EPOCH: 137 / 200\n",
      "8.23774060793221\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch136\\assets\n",
      "TRAINING EPOCH: 138 / 200\n",
      "8.23613812122494\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch137\\assets\n",
      "TRAINING EPOCH: 139 / 200\n",
      "8.235353167168796\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch138\\assets\n",
      "TRAINING EPOCH: 140 / 200\n",
      "8.221978438086808\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch139\\assets\n",
      "TRAINING EPOCH: 141 / 200\n",
      "8.217500230297446\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch140\\assets\n",
      "TRAINING EPOCH: 142 / 200\n",
      "8.209980222396553\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch141\\assets\n",
      "TRAINING EPOCH: 143 / 200\n",
      "8.210945647209883\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch142\\assets\n",
      "TRAINING EPOCH: 144 / 200\n",
      "8.184478553943336\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch143\\assets\n",
      "TRAINING EPOCH: 145 / 200\n",
      "8.18129069171846\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch144\\assets\n",
      "TRAINING EPOCH: 146 / 200\n",
      "8.18306882493198\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch145\\assets\n",
      "TRAINING EPOCH: 147 / 200\n",
      "8.18650731164962\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch146\\assets\n",
      "TRAINING EPOCH: 148 / 200\n",
      "8.166645078919828\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch147\\assets\n",
      "TRAINING EPOCH: 149 / 200\n",
      "8.15348843485117\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch148\\assets\n",
      "TRAINING EPOCH: 150 / 200\n",
      "8.149359816685319\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch149\\assets\n",
      "TRAINING EPOCH: 151 / 200\n",
      "8.148456025868654\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch150\\assets\n",
      "TRAINING EPOCH: 152 / 200\n",
      "8.127462078817189\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch151\\assets\n",
      "TRAINING EPOCH: 153 / 200\n",
      "8.146511068567634\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch152\\assets\n",
      "TRAINING EPOCH: 154 / 200\n",
      "8.134998816996813\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch153\\assets\n",
      "TRAINING EPOCH: 155 / 200\n",
      "8.130830628797412\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch154\\assets\n",
      "TRAINING EPOCH: 156 / 200\n",
      "8.123716521076858\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch155\\assets\n",
      "TRAINING EPOCH: 157 / 200\n",
      "8.11780359223485\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch156\\assets\n",
      "TRAINING EPOCH: 158 / 200\n",
      "8.108127470128238\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch157\\assets\n",
      "TRAINING EPOCH: 159 / 200\n",
      "8.10694901458919\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch158\\assets\n",
      "TRAINING EPOCH: 160 / 200\n",
      "8.113351836800575\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch159\\assets\n",
      "TRAINING EPOCH: 161 / 200\n",
      "8.117339658550918\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch160\\assets\n",
      "TRAINING EPOCH: 162 / 200\n",
      "8.122120100073516\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch161\\assets\n",
      "TRAINING EPOCH: 163 / 200\n",
      "8.09699687641114\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch162\\assets\n",
      "TRAINING EPOCH: 164 / 200\n",
      "8.087808450683951\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch163\\assets\n",
      "TRAINING EPOCH: 165 / 200\n",
      "8.096351943910122\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch164\\assets\n",
      "TRAINING EPOCH: 166 / 200\n",
      "8.078313405625522\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch165\\assets\n",
      "TRAINING EPOCH: 167 / 200\n",
      "8.073003867641091\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch166\\assets\n",
      "TRAINING EPOCH: 168 / 200\n",
      "8.086505021899939\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch167\\assets\n",
      "TRAINING EPOCH: 169 / 200\n",
      "8.07112966105342\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch168\\assets\n",
      "TRAINING EPOCH: 170 / 200\n",
      "8.065128211863339\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch169\\assets\n",
      "TRAINING EPOCH: 171 / 200\n",
      "8.059182588942349\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch170\\assets\n",
      "TRAINING EPOCH: 172 / 200\n",
      "8.049692808650434\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch171\\assets\n",
      "TRAINING EPOCH: 173 / 200\n",
      "8.040455181151628\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch172\\assets\n",
      "TRAINING EPOCH: 174 / 200\n",
      "8.043340248987079\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch173\\assets\n",
      "TRAINING EPOCH: 175 / 200\n",
      "8.055932912044227\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch174\\assets\n",
      "TRAINING EPOCH: 176 / 200\n",
      "8.037012254819274\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch175\\assets\n",
      "TRAINING EPOCH: 177 / 200\n",
      "8.01681948080659\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch176\\assets\n",
      "TRAINING EPOCH: 178 / 200\n",
      "8.012545094825327\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch177\\assets\n",
      "TRAINING EPOCH: 179 / 200\n",
      "8.019688654690981\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch178\\assets\n",
      "TRAINING EPOCH: 180 / 200\n",
      "7.97849219571799\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch179\\assets\n",
      "TRAINING EPOCH: 181 / 200\n",
      "8.02520908601582\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch180\\assets\n",
      "TRAINING EPOCH: 182 / 200\n",
      "8.003624786622822\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch181\\assets\n",
      "TRAINING EPOCH: 183 / 200\n",
      "7.992371185682714\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch182\\assets\n",
      "TRAINING EPOCH: 184 / 200\n",
      "7.996505775488913\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch183\\assets\n",
      "TRAINING EPOCH: 185 / 200\n",
      "7.992751508951187\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch184\\assets\n",
      "TRAINING EPOCH: 186 / 200\n",
      "7.977993808686733\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch185\\assets\n",
      "TRAINING EPOCH: 187 / 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.971891804598272\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch186\\assets\n",
      "TRAINING EPOCH: 188 / 200\n",
      "7.966007037088275\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch187\\assets\n",
      "TRAINING EPOCH: 189 / 200\n",
      "7.961614770814776\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch188\\assets\n",
      "TRAINING EPOCH: 190 / 200\n",
      "7.949115961790085\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch189\\assets\n",
      "TRAINING EPOCH: 191 / 200\n",
      "7.9254083735868335\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch190\\assets\n",
      "TRAINING EPOCH: 192 / 200\n",
      "7.967363802716136\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch191\\assets\n",
      "TRAINING EPOCH: 193 / 200\n",
      "7.940149042755365\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch192\\assets\n",
      "TRAINING EPOCH: 194 / 200\n",
      "7.9245038675144315\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch193\\assets\n",
      "TRAINING EPOCH: 195 / 200\n",
      "7.953505014069378\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch194\\assets\n",
      "TRAINING EPOCH: 196 / 200\n",
      "7.930589466355741\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch195\\assets\n",
      "TRAINING EPOCH: 197 / 200\n",
      "7.922913221642375\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch196\\assets\n",
      "TRAINING EPOCH: 198 / 200\n",
      "7.912979600019753\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch197\\assets\n",
      "TRAINING EPOCH: 199 / 200\n",
      "7.918209368363023\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch198\\assets\n",
      "TRAINING EPOCH: 200 / 200\n",
      "7.90332633908838\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch199\\assets\n",
      "TRAINING EPOCH: 201 / 200\n",
      "7.89575513638556\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch200\\assets\n",
      "TRAINING EPOCH: 202 / 200\n",
      "7.9103984804823995\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch201\\assets\n",
      "TRAINING EPOCH: 203 / 200\n",
      "7.88833396974951\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch202\\assets\n",
      "TRAINING EPOCH: 204 / 200\n",
      "7.890893932431936\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch203\\assets\n",
      "TRAINING EPOCH: 205 / 200\n",
      "7.873415405862033\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch204\\assets\n",
      "TRAINING EPOCH: 206 / 200\n",
      "7.872317919507623\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch205\\assets\n",
      "TRAINING EPOCH: 207 / 200\n",
      "7.8683359650895\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch206\\assets\n",
      "TRAINING EPOCH: 208 / 200\n",
      "7.872924622148275\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch207\\assets\n",
      "TRAINING EPOCH: 209 / 200\n",
      "7.861619478091598\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch208\\assets\n",
      "TRAINING EPOCH: 210 / 200\n",
      "7.863675471395254\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch209\\assets\n",
      "TRAINING EPOCH: 211 / 200\n",
      "7.865185747854412\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch210\\assets\n",
      "TRAINING EPOCH: 212 / 200\n",
      "7.857715280726552\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch211\\assets\n",
      "TRAINING EPOCH: 213 / 200\n",
      "7.847168510779738\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch212\\assets\n",
      "TRAINING EPOCH: 214 / 200\n",
      "7.845566320233047\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch213\\assets\n",
      "TRAINING EPOCH: 215 / 200\n",
      "7.828034384176135\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch214\\assets\n",
      "TRAINING EPOCH: 216 / 200\n",
      "7.8347242921590805\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch215\\assets\n",
      "TRAINING EPOCH: 217 / 200\n",
      "7.831137266010046\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch216\\assets\n",
      "TRAINING EPOCH: 218 / 200\n",
      "7.814386764541268\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch217\\assets\n",
      "TRAINING EPOCH: 219 / 200\n",
      "7.818126221187413\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch218\\assets\n",
      "TRAINING EPOCH: 220 / 200\n",
      "7.81362163554877\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch219\\assets\n",
      "TRAINING EPOCH: 221 / 200\n",
      "7.793610339052975\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch220\\assets\n",
      "TRAINING EPOCH: 222 / 200\n",
      "7.809265780262649\n",
      "INFO:tensorflow:Assets written to: Model_at_epoch221\\assets\n",
      "TRAINING EPOCH: 223 / 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-82da9bb1b493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss = tf.keras.losses.MeanSquaredError())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_events\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-044a82a90071>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(model, batches)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m#print(np.shape(batch[1]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[1;31m#model.train_on_batch(x = batch[0], y = batch[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mTraining_Losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1689\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1691\u001b[1;33m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[0m\u001b[0;32m   1692\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m                                                     class_weight)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[1;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_distribute_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[0;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    700\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \", \".join(graph_rewrites))\n\u001b[0;32m    385\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         dataset = _OptimizeDataset(dataset, graph_rewrites,\n\u001b[0m\u001b[0;32m    387\u001b[0m                                    graph_rewrite_configs)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[0;32m   4394\u001b[0m     self._optimizations = ops.convert_to_tensor(\n\u001b[0;32m   4395\u001b[0m         optimizations, dtype=dtypes.string, name=\"optimizations\")\n\u001b[1;32m-> 4396\u001b[1;33m     variant_tensor = gen_dataset_ops.optimize_dataset(\n\u001b[0m\u001b[0;32m   4397\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4398\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[1;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[0;32m   3942\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3943\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3944\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3945\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OptimizeDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3946\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    \n",
    "    #model = tcn_model_26(max_length, n_filters, kernel_size, output_dim)\n",
    "    #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "    trained_model, training_losses, validation_losses = Train(model, train_events)\n",
    "    end = time.time()\n",
    "    print(round(end-start,3),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(8,10))\n",
    "ax[0].plot(training_losses)\n",
    "ax[0].set_title('Training Loss')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].plot(validation_losses[1:])\n",
    "ax[1].set_title('Validation Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    \n",
    "    pred,truth  = Predict(trained_model, train_events)#, batch_size)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(round(end-start,3),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, truth = np.concatenate(np.array(pred)), np.concatenate(np.array(truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "#ax.scatter(np.array(pred)[:,0], np.array(truth)[:,0], label='sin')\n",
    "ax.scatter(pred, truth, label='Energy', s=0.1)\n",
    "ax.legend()\n",
    "ax.plot([-0.5, 2], [-0.5, 2], 'k--')\n",
    "ax.axis('equal')\n",
    "ax.text(1,0, 'Correlation: '+ str(np.round(np.corrcoef(pred,truth)[0,1],3)))\n",
    "ax.set_xlabel('Prediction')\n",
    "ax.set_ylabel('Target')\n",
    "#ax.set_xlim([-0.2,1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.hist2d(pred, truth, bins=20)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle as pkl\n",
    "#with open('ES_predictions','wb') as f:\n",
    "#    pkl.dump(pred, f)\n",
    "#with open('ES_truths','wb') as f:\n",
    "#    pkl.dump(truth, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(truth, histtype = 'step', bins = 100, label ='truth') \n",
    "plt.hist(pred, histtype = 'step', bins = 100, label = 'pred')\n",
    "plt.legend()\n",
    "\n",
    "print('correlation: ')\n",
    "cor = np.corrcoef(pred,truth)\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
